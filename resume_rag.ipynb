{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shibin-CR7/FOXIOM/blob/main/resume_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmqrEMQ2MAlz",
        "outputId": "878f4e93-2a21-4f46-fbbc-7d7ebeec6fcd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.2/140.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.7/427.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.4/360.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement sentence_transformers--quiet (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sentence_transformers--quiet\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install pgvector --quiet\n",
        "%pip install langchain langchain-community --quiet\n",
        "%pip install chromadb --quiet\n",
        "%pip install sentence-transformers --quiet\n",
        "%pip install langchain-fireworks --quiet\n",
        "%pip install pypdf --quiet\n",
        "%pip install sentence_transformers--quiet\n",
        "%pip install chromadb --quiet\n",
        "%pip install pypdf2 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2ahW6P4_FKc",
        "outputId": "f720e437-ffb0-4fd6-e241-860d94535106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/HR_executive.zip\n",
            "  inflating: /content/HR executive/_SRILAKSHMIRATNAKARNCV.pdf  \n",
            "  inflating: /content/HR executive/AISHWARYA V.pdf  \n",
            "  inflating: /content/HR executive/AJUN SAJI 123.pdf  \n",
            "  inflating: /content/HR executive/Akshay Divakar CV-1.pdf  \n",
            "  inflating: /content/HR executive/Amrutha_R_HR_Resume.pdf  \n",
            "  inflating: /content/HR executive/Anjaly Resume..pdf  \n",
            "  inflating: /content/HR executive/anjitha vp CV.pdf  \n",
            "  inflating: /content/HR executive/Anooj_CV-2.pdf  \n",
            "  inflating: /content/HR executive/CV NEW (1).pdf  \n",
            "  inflating: /content/HR executive/DOC-20240422-WA0114_.pdf  \n",
            "  inflating: /content/HR executive/DOC-20240515-WA0009._20240521_081510_0000.pdf  \n",
            "  inflating: /content/HR executive/gayathri cv resume.pdf  \n",
            "  inflating: /content/HR executive/Gopika Updated Resumee .pdf  \n",
            "  inflating: /content/HR executive/HR CV.pdf  \n",
            "  inflating: /content/HR executive/IMG_20240107_233244-compressed.pdf  \n",
            "  inflating: /content/HR executive/Liyan Varghese CV.pdf  \n",
            "  inflating: /content/HR executive/Resume_Lakshmipriya VM_HR Professional.pdf  \n",
            "  inflating: /content/HR executive/ResumeAthulyaBS.pdf  \n",
            "  inflating: /content/HR executive/Resume-HARITHA ANIL C A.pdf  \n",
            "  inflating: /content/HR executive/ROSA JO-1.pdf  \n",
            "  inflating: /content/HR executive/Sangeetha. Image.pdf  \n",
            "  inflating: /content/HR executive/Sreelakshmi S. Resume.pdf  \n",
            "  inflating: /content/HR executive/SUKANYA.S CV..pdf  \n",
            "  inflating: /content/HR executive/Vidyap_CV_2024.pdf  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/HR_executive.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez98Rkc3bB7U"
      },
      "outputs": [],
      "source": [
        "#!export OPENAPI_API_KEY=WAtTqN0IdVMKsd8C5Zs9ixwHApIpTvJyzmiGujazA9ya1Sxf\n",
        "!export fireworks_api_key=\"WAtTqN0IdVMKsd8C5Zs9ixwHApIpTvJyzmiGujazA9ya1Sxf\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xA8okqsubB9Y"
      },
      "outputs": [],
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_community.embeddings.sentence_transformer import (\n",
        "    SentenceTransformerEmbeddings,\n",
        ")\n",
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJd4Q2M2iElj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['FIREWORKS_API_KEY'] = '6byKKVHFMZdwFFLcJqcYAkEGTVkKJ8HfqTd2SP0Z5XYZaDdS'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zf3S186oWqW",
        "outputId": "734be217-1bba-4bee-93a0-3ca0c8a1dc88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 7 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 339 0 (offset 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Contact Details  \n",
            " \n",
            "Email : sreelakshmimidhila@gmail.com  \n",
            "Phone No: 9747321465  \n",
            "Location:  Kochi  \n",
            "Linkedin:  \n",
            "https://www.linkedin.com/in/sreelaks\n",
            "hmi-s-9179aa195  \n",
            " \n",
            "SKILLS  \n",
            "• Talent Acquisition  \n",
            "• Recruitment  \n",
            "• Candidate Screening and sourcing \n",
            "through Boolean search and X-ray \n",
            "search  \n",
            "• Marketing Research using SPSS \n",
            "Software.  \n",
            "• Onboarding Process  \n",
            "• Public Relations  \n",
            "• Skilled in designing vis ually \n",
            "appealing  & interactive dashboards  \n",
            "to communicate  insights and trends \n",
            "effectively  \n",
            " \n",
            "PROJECTS  \n",
            "• Is OTT a disruption for Movie \n",
            "theatre Industry  \n",
            "• Power BI - Supply chain \n",
            "Management  \n",
            "• Crop Protection and Irrigation \n",
            "System  \n",
            "• IoT based Home automation System  \n",
            " \n",
            "ACCOMPLISHMENTS  \n",
            "• NSS Volunteer  \n",
            "• Professional Student Summit  \n",
            "• College Union Member  \n",
            " \n",
            "   SR E E L A K S H M I  S  \n",
            "   H R  A S S O C I A T E' metadata={'source': 'HR executive/Sreelakshmi S. Resume.pdf', 'page': 0}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Define a function to extract text from a PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, 'rb') as file:\n",
        "        reader = PdfReader(file)\n",
        "        text = ''\n",
        "        for page_num in range(len(reader.pages)):\n",
        "            page = reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Directory containing PDFs\n",
        "pdf_directory = \"./HR executive\"\n",
        "\n",
        "# Load documents from the directory\n",
        "loader = PyPDFDirectoryLoader(pdf_directory)\n",
        "documents = loader.load()\n",
        "\n",
        "# Split documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(documents)\n",
        "\n",
        "# Extract text and store with filenames\n",
        "all_texts = []\n",
        "for filename in os.listdir(pdf_directory):\n",
        "    if filename.endswith('.pdf'):\n",
        "       pdf_path = os.path.join(pdf_directory, filename)\n",
        "       text = extract_text_from_pdf(pdf_path)\n",
        "       all_texts.append({\"text\": text, \"file_name\": filename})\n",
        "\n",
        "#Example: Display the first split chunk and the first extracted text with filename\n",
        "print(splits[0])\n",
        "#print(all_texts[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmEhWJ-XxnfP"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "client = chromadb.Client(Settings())\n",
        "collection = client.create_collection(name=\"HR_docs\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ez3nekiGyDjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44222a1c-52b8-45c9-ee17-0a6865d5cdda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:01<00:00, 75.3MiB/s]\n"
          ]
        }
      ],
      "source": [
        "for idx, split in enumerate(splits):\n",
        "    collection.add(\n",
        "        documents=[split.page_content],\n",
        "        metadatas=[{\"filename\": split.metadata[\"source\"]}],\n",
        "        ids=[f\"split_{idx}\"]\n",
        "    )\n",
        "\n",
        "result = collection.get([\"split_0\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEvq739o_ZB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c0a3374-9650-4e28-98d6-991345770457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 0.4. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "# Initialize Chroma retriever\n",
        "retriever = Chroma(client=client, collection_name=\"HR_docs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i7pt93TkRJ4"
      },
      "outputs": [],
      "source": [
        "from langchain_fireworks import Fireworks\n",
        "llm = Fireworks(\n",
        "    model=\"accounts/fireworks/models/mixtral-8x7b-instruct\",\n",
        "    temperature=0.0,\n",
        "    max_tokens=2000,\n",
        "    top_k=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOPQereRCMOl"
      },
      "outputs": [],
      "source": [
        "job_description = \"\"\"\n",
        "We are seeking a motivated HR Executive with  1-2 years of experience, preferably from an IT background.\n",
        "\"\"\"\n",
        "question = \"Please extract and format the candidate details as specified.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLXWuSdbAgRT",
        "outputId": "b9f5458e-dbcc-4d41-e372-ee26ec44d05a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "answer:\n",
            "\n",
            "name: SR E E L A K S H M I  S\n",
            "contact:\n",
            "    email: sreelakshmimidhila@gmail.com\n",
            "    phone: 9747321465\n",
            "experience:\n",
            "   1. Not specified in the resume\n",
            "skills: \n",
            "   1. Talent Acquisition\n",
            "   2. Recruitment\n",
            "   3. Candidate Screening and sourcing through Boolean search and X-ray search\n",
            "   4. Marketing Research using SPSS Software\n",
            "   5. Onboarding Process\n",
            "   6. Public Relations\n",
            "   7. Skilled in designing visually appealing & interactive dashboards to communicate insights and trends effectively\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Updated template to include the text chunk\n",
        "template = \"\"\"\n",
        "You are an AI language model assistant. Your task is to evaluate a pool of resumes against the following job description (JD) and collect specific details about each candidate to determine their suitability.\n",
        "\n",
        "Job Description (JD):\n",
        "{job_description}\n",
        "\n",
        "Resume:\n",
        "{text_chunk}\n",
        "\n",
        "For each candidate, please extract the following information in the specified format:\n",
        "\n",
        "name: <candidate name>\n",
        "contact:\n",
        "    email: <email>\n",
        "    phone: <phone number>2\n",
        "experience:\n",
        "    1. <role_name1> - <start_date1> to <end_date1>\n",
        "    2. <role_name2> - <start_date2> to <end_date2>\n",
        "    3. <role_name3> - <start_date3> to <end_date3>\n",
        "skills: <skill1>, <skill2>, <skill3>, ...\n",
        "\n",
        "question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# Function to format input using the prompt template\n",
        "def format_input(job_description, question, text_chunk):\n",
        "    return prompt_perspectives.format(job_description=job_description, question=question, text_chunk=text_chunk)\n",
        "\n",
        "# Initialize an empty list to store candidate details\n",
        "candidate_details = []\n",
        "\n",
        "# Process each text chunk with the LLM\n",
        "for split in splits:\n",
        "    input_text = format_input(job_description, question, split.page_content)\n",
        "    response = llm(input_text)\n",
        "    candidate_details.append(response)\n",
        "\n",
        "# Display the first set of candidate details\n",
        "print(candidate_details[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQSjs4hSSMWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kD4Cl8h2SMUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h33sQOnuSMR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WU0eQAQhSMQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3cTebS1luX0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u62GvAndluVM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXDV03LFluTi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}